{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11435/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: could not connect to ollama app, is it running?\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as articles, social media posts, product descriptions, and more. This helps businesses save time and resources on content creation.\n",
      "2. **Product Design and Development**: Generative AI can aid in designing new products, such as 3D models, prototypes, and even entire product lines. This can help companies reduce development costs and time-to-market.\n",
      "3. **Personalized Marketing**: AI-powered tools can generate personalized marketing messages, emails, and ads based on customer data and behavior. This helps businesses tailor their marketing efforts to specific audience segments.\n",
      "4. **Image and Video Editing**: Generative AI can be used to edit images and videos, creating realistic and engaging visuals for various applications, such as advertising, social media, and entertainment.\n",
      "5. **Chatbots and Virtual Assistants**: AI-powered chatbots can be used to provide customer support, answer frequently asked questions, and even engage in basic conversations.\n",
      "6. **Predictive Analytics**: Generative AI algorithms can analyze large datasets to identify patterns and make predictions about future outcomes. This helps businesses make data-driven decisions and optimize operations.\n",
      "7. **Automated Writing Assistance**: AI-powered writing tools can assist writers with tasks such as suggesting alternative phrases, grammar correction, and even generating entire drafts.\n",
      "8. **Music and Audio Generation**: Generative AI can create original music tracks, sound effects, and audio content for various applications, such as film, gaming, and advertising.\n",
      "9. **Customer Service Automation**: AI-powered chatbots can be used to automate customer service tasks, freeing up human representatives to focus on more complex issues.\n",
      "10. **Data Augmentation**: Generative AI algorithms can generate new, high-quality data samples to augment existing datasets, helping businesses improve the accuracy of their machine learning models.\n",
      "\n",
      "Some notable companies that are leveraging generative AI include:\n",
      "\n",
      "* **Google**: Using generative AI for image and video editing, as well as developing new tools for content generation.\n",
      "* **Amazon**: Utilizing AI-powered chatbots for customer service and using generative AI to create personalized product recommendations.\n",
      "* **Microsoft**: Developing AI-powered tools for content creation, such as the Microsoft Bot Framework.\n",
      "* **Adobe**: Using generative AI for image editing and manipulation, as well as creating new tools for digital marketing and advertising.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Use cases like article writing, social media content creation, and product descriptions can be automated with generative AI models.\n",
      "2. **Graphic Design and Visual Content Creation**: AI-powered tools can generate images, logos, and graphics for branding, marketing materials, and packaging designs.\n",
      "3. **Music Composition and Audio Post-Production**: Generative AI can create music tracks, sound effects, and audio loops for films, TV shows, and video games.\n",
      "4. **Chatbots and Virtual Assistants**: AI-powered chatbots can be generated to provide customer support, answer frequently asked questions, and offer personalized recommendations.\n",
      "5. **Marketing Automation**: Generative AI can help automate marketing campaigns by generating personalized emails, social media posts, and ad copy.\n",
      "6. **Image Editing and Enhancement**: AI-powered tools can enhance or generate images for advertising, e-commerce, and other applications.\n",
      "7. **Data Visualization**: Generative AI can create data-driven visualizations to help businesses communicate complex data insights more effectively.\n",
      "8. **Customer Segmentation and Personalization**: AI-powered algorithms can segment customers based on behavior, demographics, and preferences, enabling personalized marketing campaigns.\n",
      "9. **Product Design and Development**: Generative AI can assist in designing new products by generating 3D models, prototypes, and simulations.\n",
      "10. **Predictive Maintenance and Quality Control**: Machine learning-based predictive models can analyze sensor data to predict equipment failures or quality control issues.\n",
      "11. **Cybersecurity Threat Analysis**: AI-powered tools can analyze threat patterns, detect anomalies, and predict potential security breaches.\n",
      "12. **Data Analysis and Insights**: Generative AI can help extract insights from large datasets by identifying trends, patterns, and correlations.\n",
      "13. **Language Translation and Localization**: AI-powered translation models can generate human-like translations for marketing materials, websites, and customer communications.\n",
      "14. **Video Production and Editing**: Generative AI can assist in video production by generating graphics, special effects, and even entire scenes.\n",
      "15. **Supply Chain Optimization**: AI-powered predictive models can analyze supply chain data to optimize logistics, predict demand, and reduce costs.\n",
      "\n",
      "These applications are just a few examples of the many business uses of generative AI. As this technology continues to evolve, we can expect to see even more innovative applications across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "client = Client(host=\"http://localhost:11435\")\n",
    "\n",
    "response = client.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation:** Generative AI can be used to create customized content such as social media posts, blog articles, and product descriptions that mimic human writing styles.\n",
      "2. **Digital Marketing:** AI-powered generative models can help with personalized marketing campaigns, generating ad copy, email newsletters, and promotional materials tailored to individual customers' preferences.\n",
      "3. **Personalization:** Generative AI algorithms can analyze customer data and behavior, providing personalized recommendations for products or services based on their past interactions.\n",
      "4. **Virtual Assistants:** AI-powered virtual assistants, like chatbots, use generative models to understand user queries and generate responses that mimic human-like conversations.\n",
      "5. **Product Design:** Generative AI can aid in product design by generating 3D models, prototypes, and concept designs based on customer feedback and preferences.\n",
      "6. **Image Generation for Advertising:** AI-powered generative models can create custom images, animations, or graphics to enhance advertising campaigns and make them more engaging.\n",
      "7. **Voice Over Scripting:** Generative AI algorithms can generate voice-over scripts for videos, podcasts, or commercials in multiple languages, reducing production costs and increasing versatility.\n",
      "8. **Business Intelligence:** Generative AI models can analyze large datasets to identify trends, patterns, and predictions, aiding businesses in making informed decisions about resource allocation and market strategy.\n",
      "9. **Document Automation:** Generative AI-powered templates can automate document generation such as letters of intent, contracts, or invoices by suggesting drafts based on industry standards.\n",
      "10. **User Experience (UX):** Generative models can help designers generate user interface concepts and design personas to develop more intuitive and engaging interfaces.\n",
      "\n",
      "Some specific industries that have seen significant applications of generative AI include:\n",
      "\n",
      "1. Finance: Loan underwriting and application generation\n",
      "2. Healthcare: Personalized medicine, genomic analysis, and medical writing\n",
      "3. Education: Customized learning materials and assessment tools\n",
      "4. Customer Service: Chatbots, automated support, and sentiment analysis\n",
      "5. Supply Chain Management: Predictive analytics for demand forecasting, inventory management\n",
      "\n",
      "Generative AI can significantly enhance operational efficiency and cost savings across various industries, driving innovation in customer engagement, product development, and business growth.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11435/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I'm trying to understand what LLMs are. From what I know, they're called \"large language models,\" which probably means they can handle a lot of text. But I've also heard them referred to as \"pre-trained big models.\" Hmm.\n",
      "\n",
      "So, first, what's a neural network? I think it has something to do with layers and neurons, right? Maybe like in the human brain or maybe with algorithms that have multiple layers. They process information through weights and biases, making decisions based on patterns they detect. It must be really efficient because if that's the case, why would you need something called an attention transformer?\n",
      "\n",
      "Wait, the user mentioned transformation of vectors into output vectors using self-attention. Self-attention sounds familiar; maybe it's a way the neural network processes different parts of the text together. Like when it sees words and phrases, it doesn't just process each one independently but considers how they relate to each other.\n",
      "\n",
      "And attention focuses on paying attention to certain elements in the input. So while processing the text, the model can decide which word or sentence is most relevant for understanding something. That's different from a regular neural network that might consider everything without focusing on the key parts it needs for output.\n",
      "\n",
      "The Transformer architecture seems more complex because it's called so. It has multiple layers and perhaps a more detailed structure than typical feed-forward networks. I believe it uses self-attention to handle sequential data, which is great for understanding context in text.\n",
      "\n",
      "Putting this all together, an LLM using a Transformer model would process input through layered neural networks that consider the relationships between different parts of the text, paying attention to important elements while integrating them for the final output. This way, it can generate coherent and relevant responses from vast amounts of text without needing human intervention, hence \"pre-trained big models.\"\n",
      "</think>\n",
      "\n",
      "An LLM (large language model) is a type of artificial intelligence designed to produce human-like text or speech by learning patterns in data from publicly available sources. The core concepts behind LLMs include:\n",
      "\n",
      "1. **Neural Network**: \n",
      "   - A neural network is composed of multiple layers, each containing nodes (also called neurons) connected with weighted connections. These networks learn and model patterns through the weights of these connections. They process information by summing and applying non-linear activation functions to input vectors.\n",
      "\n",
      "2. **Attention**:\n",
      "   - Attention mechanism allows models to focus on specific parts of their input. It emphasizes certain elements within a sequence, enabling the model to pay attention to relevant information while ignoring less important context units.\n",
      "\n",
      "3. **Transformer Architecture (Self-attention)**:\n",
      "   - The Transformer is structured into multiple layers with self-attention, a property where each layer processes all words simultaneously using a self-attention mechanism. This allows models to process sequential data by considering relationships, capturing long-range dependencies in text.\n",
      "\n",
      "A large language model uses these components within a Transformer architecture, integrating attention for focused processing of relevant elements and generating contextually relevant responses through layered neural networks.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Der Text beschreibt das Album \"MushMix\" des Berliner Gitarristen Jörg Schippa im TEKK-Trio, der gemeinsam mit Silke Eberhard und Horst Nonnenmacher improvisierte Musik macht. Hier sind einige Schlüsselaspekte, die aus dem Text hervorgehen:\n",
       "\n",
       "*   **Improvisierte Musik**: Das Album \"MushMix\" ist ein Improvisationsprojekt, bei dem die drei Musiker gemeinsam experimentelle und kreative Musik erstellen.\n",
       "*   **TEKK-Trio**: Der TEKK-Trio ist ein improvisiertes Trio, das sich aus Jörg Schippa (Gitarrist), Silke Eberhard (Saxophonistin) und Horst Nonnenmacher (Bassisten) zusammensetzt. Das Trio spielt eine Mischung aus Rock, Blues, Funk und Jazz.\n",
       "*   **Interaktionen**: Die Texte betonen die Bedeutung der Interaktion zwischen den drei Musikern. Sie spielen \"spontane Falschfährten\" und wandeln diese in Überraschungsmomente um, die dem Hörer einen kontinuierlichen Strom unerwarteter Vergnügens beschert.\n",
       "*   **Experimentelle Musik**: Das Album zeigt eine experimentelle und kreative Seite der Musik von Jörg Schippa. Die Texte sprechen von \"rockigen beschwingten Melodien\" und einem \"musikalischem Humor\", die in der Musik zum Ausdruck kommen.\n",
       "*   **Berlin und die Jazzszene**: Der Text erwähnt, dass das TEKK-Trio im Hannes Zerbe Jazz Orchester aktiv ist. Dies unterstreicht die Verbindung zwischen dem Trio und der Berliner Jazzszene.\n",
       "*   **Einflüsse und Stil**: Die Musik des TEKK-Trio wirft Einflüsse von Rock, Blues und Klassik ab, was zu einem einzigartigen Sound führt.\n",
       "\n",
       "Durch das Album \"MushMix\" zeigt Jörg Schippa seine musikalische Vielfalt und experimentelle Natur."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 0. Instantiate an Ollama client\n",
    "\n",
    "client = Client(host=\"http://localhost:11435\")\n",
    "\n",
    "# 1. Write class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "# 2. Website example\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "\n",
    "# 3. Define the System Prompt\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "# 4. A function that writes an User Prompt that asks for summaries of websites\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "# 5. Create message arr for request\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "# 6. Summarize with Ollama\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = client.chat(model=MODEL, messages=messages_for(website))\n",
    "    return response.message.content\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "display_summary(\"https://joergschippa.de/wordpress/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d839a9-35a4-4f60-b700-1a65f9a6e624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
